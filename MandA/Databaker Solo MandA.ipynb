{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the paths to the code sorted out.  This is the wrong way to do it, and it needs sorting out as to the correct way\n",
    "# Might need pip install developer mode so that a symlink is made to the databakersolo source code from the git checkout\n",
    "# rather than it being copied deep into the site-packages directory tree\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/goatchurch/sensiblecode/databaker\")\n",
    "sys.path.insert(0, \"/home/goatchurch/sensiblecode/xypath\")\n",
    "sys.path.insert(0, \"/home/goatchurch/sensiblecode/messytables\")\n",
    "sys.path.insert(0, \"/home/goatchurch/datalogging/anaconda3/lib/python3.5/site-packages/\")  # for xlrd\n",
    "sys.path.insert(0, \"/home/goatchurch/datalogging/anaconda3/lib/python3.5/site-packages/xlutils-2.0.0-py3.5.egg/\")  # for xlutils\n",
    "import databaker\n",
    "import databaker.constants\n",
    "import xlutils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following is a block of code copied directly from an actual recipe without any changes\n",
    "\n",
    "from databaker.constants import *\n",
    "\n",
    "def per_file(tabs):    \n",
    "    return PARAMS(0)\n",
    "\n",
    "def per_tab(tab):           \n",
    "     \n",
    "    my_dict = {\"6A_Top\": 'CBAQ', \"6A_Bottom\": 'HCL3', \"6D_Top\": 'CBAS', \"6D_Bottom\":'HCL5',\n",
    "               \"7A_Top\": 'CBAU', \"7A_Bottom\": 'HCK7', \"7D_Top\": 'CBAW', \"7D_Bottom\":'HCK9',\n",
    "    }\n",
    "\n",
    "    anchor = tab.filter(contains_string (my_dict[PARAMS(1)]))\n",
    "    obs = anchor.shift(DOWN).expand(RIGHT).expand(DOWN).is_not_blank()\n",
    "\n",
    "    # Getting all the junk out of the file\n",
    "    unwanted = tab.excel_ref('AA1').expand(DOWN).expand(RIGHT)     \n",
    "    unwanted = unwanted | anchor.expand(DOWN).filter(contains_string ('Area Analysis')).expand(RIGHT).expand(DOWN)\n",
    "    unwanted = unwanted | tab.filter(contains_string ('indicates earliest revision')).expand(RIGHT).expand(DOWN)\n",
    "    unwanted = unwanted | anchor.expand(DOWN).filter(contains_string ('Number')).shift(UP).expand(RIGHT).expand(DOWN)\n",
    "    obs = obs - unwanted    \n",
    "    \n",
    "    # Dimension etc\n",
    "    anchor.shift(0, -2).expand(RIGHT).is_not_blank().dimension(\"Area\", CLOSEST, LEFT)\n",
    "    anchor.shift(0, -1).expand(RIGHT).is_not_blank().dimension(MEASURETYPE, DIRECTLY, ABOVE)\n",
    "    anchor.shift(-1, 0).expand(DOWN).is_not_blank().dimension(TIME, DIRECTLY, LEFT)        \n",
    "    \n",
    "    cat = tab.filter(contains_string (PARAMS(1)[0:2])).shift(RIGHT)\n",
    "    cat.dimension(\"Mergers\", CLOSEST, ABOVE)\n",
    "\n",
    "    tab.dimension(\"Companies\", \"TempValue\")\n",
    "    \n",
    "    yield obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is a set of parameters copied from a command in the batch file\n",
    "sys.argv = [\"Mergers_6_7_recipe.py\", \"--preview\", \"rftmatables_tcm77-415727.xls\", \"Table 6\", \"6A_Top\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import databaker.databakersolo as ds\n",
    "Opt = ds.Options()\n",
    "ds.Globrecipeper_file = per_file\n",
    "ds.Globrecipeper_tab = per_tab\n",
    "databaker.utils.showtime_enabled = Opt.timing\n",
    "databaker.constants.constant_params = Opt.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following loop works (if there are multiple files), but here there is almost always only one, \n",
    "# so we are going to unroll it and inline the big DBSper_fileFUNC() function\n",
    "#for fn in Opt.xls_files:\n",
    "#    ds.DBSper_fileFUNC(fn, Opt)\n",
    "spreadsheet = Opt.xls_files[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list table names is ['Table 6']\n"
     ]
    }
   ],
   "source": [
    "# Load in the table set and apply the given recipe.per_file() filter\n",
    "tableset = xypath.loader.table_set(spreadsheet, extension='xls')\n",
    "tabsfilter = per_file(tableset)   # function from the recipe\n",
    "tabs = list(xypath.loader.get_sheets(tableset, tabsfilter))   \n",
    "print(\"The list table names is\", [ tab.name  for tab in tabs ])\n",
    "\n",
    "# This concludes the business of the per_file() recipe function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got header Area: 103.117s,  3164.594s total\n",
      "got header MEASURETYPE: 0.000s,  3164.595s total\n",
      "got header TIME: 0.000s,  3164.595s total\n",
      "got header Mergers: 0.003s,  3164.598s total\n",
      "got header Companies: 0.000s,  3164.598s total\n"
     ]
    }
   ],
   "source": [
    "# Now we unroll the blocks of \"yields\" of segments given in the recipe.per_tab() function\n",
    "\n",
    "conversionsegments = [ ]   # [ (tab, {int:dimension}, [obs]) ]\n",
    "for tab in tabs:\n",
    "    segmentgenerator = per_tab(tab)   # function from recipe\n",
    "    if isinstance(segmentgenerator, xypath.xypath.Bag):\n",
    "        segmentgenerator = [segmentgenerator]    # backward compatibility for return cases\n",
    "\n",
    "    for segment in segmentgenerator:  # must be yielded so we can copy out tab.headers which are set between the function calls\n",
    "        assert tab.headernames == [None]+[tab.headers[i].Dlabel  for i in range(1, max(tab.headers.keys())+1)]  # prove we can recreate the data\n",
    "        conversionsegments.append((tab, tab.headers, segment))\n",
    "        tab.headers, tab.max_header, tab.headernames = {}, 0, [None]  # reset the hidden list of dimensions/headers back to empty before the next block\n",
    "\n",
    "# This concludes all the business of the per_tab() recipe function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rftmatables_tcm77-415727.xls':'Table 6' has 2176 cells of which 100 have been selected\n",
      "    Dim:-6 'GEOG' has 10 headercells and is looked up in the (0, -1) direction\n",
      "    Dim:-2 'STATUNIT' has 46 headercells and is looked up in the (-1, 0) direction\n",
      "    Dim:1 'Area' has 5 headercells and is looked up in the (-1, 0) direction\n",
      "    Dim:2 'Mergers' has 1 headercells and is looked up in the (0, -1) direction\n",
      "    Dim:3 'Companies' has 2176 headercells and is looked up in the None direction\n"
     ]
    }
   ],
   "source": [
    "# Provide a quick summary of the conversions that have been scheduled\n",
    "for conversionsegment in conversionsegments:\n",
    "    tab, headers, segment = conversionsegment\n",
    "    print(\"'%s':'%s' has %d cells of which %d have been selected\" % (spreadsheet, tab.name, len(tab), len(segment)))\n",
    "    for i, header in sorted(headers.items()):\n",
    "        label = header.Dlabel\n",
    "        if isinstance(label, int) and label < 0:\n",
    "            label = databaker.constants.template.dimension_names[-label]\n",
    "        print(\"    Dim:%d '%s' has %d headercells and is looked up in the %s direction\" % (i, label, len(header.bag), str(header.direction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preview file 'preview-rftmatables_tcm77-415727-Mergers_6_7_recipe-Table 6,6A_Top.xls'\n"
     ]
    }
   ],
   "source": [
    "# This code block produces the preview spreadsheet if required.  \n",
    "# We could intervene and plot the values of headers in an array to show how they are lining up\n",
    "if Opt.preview:\n",
    "    writer = xlutils.copy.copy(tableset.workbook)\n",
    "    previewfilename = ds.filenames(spreadsheet, Opt)['preview']\n",
    "    writer.save(previewfilename)\n",
    "    for tab, headers, segment in conversionsegments:\n",
    "        tableset = xypath.loader.table_set(previewfilename, extension='xls')   # load and save between each one\n",
    "        writer = xlutils.copy.copy(tableset.workbook)\n",
    "        ds.make_preview(writer, tab.index, headers, segment)\n",
    "    print(\"Saving preview file '%s'\" % previewfilename)\n",
    "    writer.save(previewfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goatchurch/sensiblecode/databaker/databaker/utils.py:47: UserWarning: Couldn't identify date '2010Â²'\n",
      "  warnings.warn(\"Couldn't identify date {!r}\".format(date))\n"
     ]
    }
   ],
   "source": [
    "# We now do the conversions from the observations to the headers (This is the slow part)\n",
    "batchrows = [ ]\n",
    "for tab, headers, segment in conversionsegments:\n",
    "    headernames = [None]+[headers[i].Dlabel  for i in range(1, max(headers)+1)]  # recreate value used in output conversion\n",
    "    for ob_num, ob in enumerate(segment):\n",
    "        values = ds.extract_dimension_values_for_ob(headers, ob, Opt.no_lookup_error)\n",
    "        batchrows.append((values, headernames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputting file 'data-rftmatables_tcm77-415727-Mergers_6_7_recipe-Table 6,6A_Top.csv' with 100 lines\n",
      "The headerrow is: ['observation', 'data_marking', 'statistical_unit_eng', 'statistical_unit_cym', 'measure_type_eng', 'measure_type_cym', 'observation_type', 'empty', 'obs_type_value', 'unit_multiplier', 'unit_of_measure_eng', 'unit_of_measure_cym', 'confidentuality', 'empty1', 'geographic_area', 'empty2', 'empty3', 'time_dim_item_id', 'time_dim_item_label_eng', 'time_dim_item_label_cym', 'time_type', 'empty4', 'statistical_population_id', 'statistical_population_label_eng', 'statistical_population_label_cym', 'cdid', 'cdiddescrip', 'empty5', 'empty6', 'empty7', 'empty8', 'empty9', 'empty10', 'empty11', 'empty12', 'dim_id_1', 'dimension_label_eng_1', 'dimension_label_cym_1', 'dim_item_id_1', 'dimension_item_label_eng_1', 'dimension_item_label_cym_1', 'is_total_1', 'is_sub_total_1', 'dim_id_2', 'dimension_label_eng_2', 'dimension_label_cym_2', 'dim_item_id_2', 'dimension_item_label_eng_2', 'dimension_item_label_cym_2', 'is_total_2', 'is_sub_total_2', 'dim_id_3', 'dimension_label_eng_3', 'dimension_label_cym_3', 'dim_item_id_3', 'dimension_item_label_eng_3', 'dimension_item_label_cym_3', 'is_total_3', 'is_sub_total_3']\n"
     ]
    }
   ],
   "source": [
    "# This is the final stage for outputting the bloated csv file\n",
    "csv_file = ds.filenames(spreadsheet, Opt)['csv']\n",
    "csv = ds.TechnicalCSV(csv_file, Opt.no_lookup_error)\n",
    "\n",
    "# write the headers put out in the file\n",
    "tab, headers, segment = conversionsegments[0]\n",
    "headernames = [None]+[headers[i].Dlabel  for i in range(1, max(headers)+1)]  # recreate value used in output conversion\n",
    "headerrow = csv.generate_header_row(headers, headernames)\n",
    "csv.csv_writer.writerow(headerrow)  # note that only first batch of headernames is used\n",
    "\n",
    "print(\"Outputting file '%s' with %d lines\" % (csv_file, len(batchrows)))\n",
    "print(\"The headerrow is:\", headerrow)\n",
    "\n",
    "# this spits out the actual rows\n",
    "for values, headernames in batchrows:\n",
    "    output_row = ds.yield_dimension_values(values, headernames)\n",
    "    csv.output(output_row)\n",
    "csv.footer()   # this closes the file\n",
    "\n",
    "# And we're done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
